{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dab08a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time, os\n",
    "import numpy as np\n",
    "from fake_useragent import UserAgent\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2e4f394",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error occurred during loading data. Trying to use cache server https://fake-useragent.herokuapp.com/browsers/0.1.11\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/metis/lib/python3.8/site-packages/fake_useragent/utils.py\", line 154, in load\n",
      "    for item in get_browsers(verify_ssl=verify_ssl):\n",
      "  File \"/opt/anaconda3/envs/metis/lib/python3.8/site-packages/fake_useragent/utils.py\", line 99, in get_browsers\n",
      "    html = html.split('<table class=\"w3-table-all notranslate\">')[1]\n",
      "IndexError: list index out of range\n"
     ]
    }
   ],
   "source": [
    "ua = UserAgent()\n",
    "user_agent = {'User-Agent': ua.random}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7da063da",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_dict = {'equity':[],\n",
    "               'publishing_analysts':[],\n",
    "               'enterprise_value':[],\n",
    "               'market_cap':[],\n",
    "               'avg_vol':[],\n",
    "               'bso':[],\n",
    "               'float_shares':[],\n",
    "               'roa':[],\n",
    "               'roe':[],\n",
    "               'ltm_rev':[],\n",
    "               'gross_profit':[],\n",
    "               'operating_margin':[],\n",
    "               'ltm_ebitda':[],\n",
    "               'mrq_assets':[]\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9c636dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CAN TAKE >8 HOURS TO RUN\n",
    "# THIS CAN TAKE >8 HOURS TO RUN\n",
    "# THIS CAN TAKE >8 HOURS TO RUN\n",
    "# THIS CAN TAKE >8 HOURS TO RUN\n",
    "# THIS CAN TAKE >8 HOURS TO RUN\n",
    "# THIS CAN TAKE >8 HOURS TO RUN\n",
    "\n",
    "def get_ticker_data(ticker):\n",
    "    \n",
    "    temp_dict = {}\n",
    "    try:\n",
    "        # set url paths and BS pages based on input ticker\n",
    "        statistics_url = f'https://finance.yahoo.com/quote/{ticker}/key-statistics?p={ticker}'\n",
    "        analysis_url = f'https://finance.yahoo.com/quote/{ticker}/analysis?p={ticker}'\n",
    "        bs_url = f'https://finance.yahoo.com/quote/{ticker}/balance-sheet?p={ticker}'\n",
    "                     \n",
    "        statistics_page = BeautifulSoup(requests.get(statistics_url,headers=user_agent).text,'html.parser')\n",
    "        bs_page = BeautifulSoup(requests.get(bs_url,headers=user_agent).text,'html.parser')\n",
    "        analysis_page = BeautifulSoup(requests.get(analysis_url,headers=user_agent).text,'html.parser')\n",
    "        \n",
    "        \n",
    "        # get publishing analyst count\n",
    "        publishing_analysts = analysis_page.find_all('span',class_='Trsdu(0.3s)')[16].text\n",
    "        \n",
    "        # get enterprise value\n",
    "        enterprise_value = statistics_page.find_all('td')[8].text\n",
    "        \n",
    "        # get market cap\n",
    "        market_cap = statistics_page.find_all('td')[1].text\n",
    "        \n",
    "        # get avg volume\n",
    "        avg_vol = statistics_page.find_all('tr',class_='Bxz(bb) H(36px) BdY Bdc($seperatorColor)')[1].text\n",
    "        \n",
    "        # get basic shares outstanding\n",
    "        bso = statistics_page.find_all('td',class_='Fw(500) Ta(end) Pstart(10px) Miw(60px)')[8].text\n",
    "        \n",
    "        # get float shares\n",
    "        float_shares = statistics_page.find_all('tr',class_='Bxz(bb) H(36px) BdB Bdbc($seperatorColor)')[9].text\n",
    "        \n",
    "        # get roa\n",
    "        roa = statistics_page.find_all('tr',class_='Bxz(bb) H(36px) BdY Bdc($seperatorColor)')[5].text\n",
    "        \n",
    "        # get roe\n",
    "        roe = statistics_page.find_all('tr',class_='Bxz(bb) H(36px) BdB Bdbc($seperatorColor)')[28].text\n",
    "        \n",
    "        # get ltm revenue\n",
    "        ltm_rev = statistics_page.find_all('tr',class_='Bxz(bb) H(36px) BdY Bdc($seperatorColor)')[6].text\n",
    "        \n",
    "        # get gross profit dollars\n",
    "        gross_profit = statistics_page.find_all('tr',class_='Bxz(bb) H(36px) BdB Bdbc($seperatorColor)')[31].text\n",
    "        \n",
    "        # get operating profit margin\n",
    "        operating_margin = statistics_page.find_all('tr',class_='Bxz(bb) H(36px) BdB Bdbc($seperatorColor)')[27].text\n",
    "        \n",
    "        # get ltm EBITDA\n",
    "        ltm_ebitda = statistics_page.find_all('tr',class_='Bxz(bb) H(36px) BdB Bdbc($seperatorColor)')[32].text\n",
    "        \n",
    "        # get mrq assets book value\n",
    "        mrq_assets = bs_page.find_all('div',class_='Ta(c) Py(6px) Bxz(bb) BdB Bdc($seperatorColor) Miw(120px) Miw(140px)--pnclg D(tbc)')[0].text\n",
    "      \n",
    "        temp_dict[ticker] = [publishing_analysts,enterprise_value,market_cap,avg_vol,\n",
    "                               bso,float_shares,roa,roe,ltm_rev,gross_profit,\n",
    "                               operating_margin,ltm_ebitda,mrq_assets]\n",
    "    \n",
    "    except IndexError:\n",
    "        temp_dict[ticker] = [np.nan,np.nan,np.nan,np.nan,\n",
    "                               np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,\n",
    "                               np.nan,np.nan,np.nan]\n",
    "        \n",
    "    return temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32064d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull Russell 1000 tickers from csv\n",
    "\n",
    "russ_df = pd.read_csv(r'/Users/sam/Desktop/russ_1000.csv')\n",
    "ticker_list = list(russ_df.Symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d4f3689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add ticker info to dictionary for dataframe\n",
    "# THIS CAN TAKE >8 HOURS TO RUN\n",
    "# THIS CAN TAKE >8 HOURS TO RUN\n",
    "# THIS CAN TAKE >8 HOURS TO RUN\n",
    "\n",
    "ticker_dict = {}\n",
    "for i in ticker_list:    \n",
    "    ticker_dict.update(get_ticker_data(i))\n",
    "    time.sleep(25 + 5*random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f6ee3791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "df = pd.DataFrame(ticker_dict).T\n",
    "df.reset_index(inplace=True)\n",
    "df.columns = ['equity','publishing_analysts','enterprise_value','market_cap','avg_vol',\n",
    "              'bso','float_shares','roa','roe','ltm_rev','gross_profit',\n",
    "              'operating_margin','ltm_ebitda','mrq_assets']\n",
    "df.dropna(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "32cb007e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to csv\n",
    "df.to_csv(r'/Users/sam/Desktop/raw_ticker_df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
